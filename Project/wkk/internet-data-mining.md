# 互联网数据挖掘

万小军 http://www.icst.pku.edu.cn/lcwm

<!-- MarkdownTOC -->

- 互联网挖掘概述
- 文本信息检索
    - 文档表示
    - 文档索引
        - 倒排索引(inverted index)
    - 文本信息检索模型
        - 布尔模型(Boolean Model)
        - 向量空间模型(Vector Space Model)
        - 概率模型(Probabilistic Model)
    - 信息检索评价
- Web 检索
    - Web 页面采集
    - Web 页面排序
    - Web 链接分析
    - 基于学习的网页排序
    - 搜索引擎优化(SEO)
- 自然语言处理基础
    - 基本任务
    - 为什么如此之难
    - 推荐教材
    - 汉语自动分词
    - 词性标注(POS Tagging)
    - 句法分析
- 数据挖掘概述与关联规则挖掘
    - 数据挖掘流程
    - 数据挖掘任务
    - 关联规则挖掘：定义
    - 摘要
    - 回归
    - 偏差/异常检测
    - 数据挖掘工具
    - 数据挖掘的挑战
- 分类
    - 基于规则的分类
    - 基于统计的分类
    - 文本统计分类流程
    - 文本分类-特征向量表示
    - 文本分类-特征选择
    - 朴素贝叶斯分类
    - Rocchio 分类方法
    - K 近邻分类方法
    - 支持向量机 Support Vector Machine
    - 分类结果评估
    - 如何应用于实际
- 聚类
    - 层次式聚类
    - K 均值(K-means)聚类
    - Buckshot 算法
    - 增量式单遍聚类(Single-Pass)
    - 基于图分割的聚类
    - 基于密度峰值的聚类(Science)
    - 半监督聚类
    - 聚类结果评估
    - 聚类算法的选择
    - 半监督聚类
    - 检索结果聚类
- 智能问答基础技术
    - 问题类型
    - 主要技术
- 互联网信息抽取
    - 文本语义信息抽取
    - 实体识别
    - 语义类挖掘

<!-- /MarkdownTOC -->

---

## 互联网挖掘概述

+ Web 挖掘
    + 由 Etzioni(1996) 提出
    + 使用数据挖掘的技术自动从 Web文档/服务发现和提取信息和知识，包括隐含的模式和关系等
+ 相关技术
    + 信息检索
    + 互联网
    + 数据库
    + 机器学习
    + 自然语言处理
    + 数据挖掘
+ 相关学术会议
    + Web 搜索: SIGIR, WWW, CIKM, WSDM
    + 数据挖掘: KDD, ICDM
    + 自然语言处理: ACL, EMNLP
    + 多媒体检索: ACM, MM
+ 应用
    + 垂直搜索
    + 个性化推荐
    + 智能问答
    + 机器翻译
    + 舆情监测
    + 情报与反恐
    + 预测

---

## 文本信息检索

+ 两个核心问题
    + 效果
        + 如何准确匹配查询与文档
        + 基于检索模型
    + 效率
        + 如何快速返回检索结果
        + 基于索引

### 文档表示
+ 元描述(Meta-descriptions)
    + 域信息(author, title, date)
    + 关键词、受控词汇
    + 分类
    + 优点
        + 主要依赖人工标注，结果比较可靠
        + 基于受控词汇的检索很高效
    + 不足
        + 人工标注非常耗时
        + 检索受限制
+ 自动文档表示
    + 词袋(Bag of Words)
        + 一篇文档由该文档中出现的词的集合所表示
        + 词语的无序集合，句法信息丢失
        + 符号化(tokenization):识别词的边界
        + 英文中大小写
        + 词语形态规范化
            + 匹配 company 和 companies? sell 与 sold?
            + 删除词语的形态信息: 时态，数量...
        + 词根(Stemming)
            + 删除后缀
            + 基于规则进行(例如 Porter's stemmer)
            + Stemming 的结果可能不是词语
            + 不相关的词可能具有相同的 stem
        + 词形还原(Lemmatization)
            + 将词语变为其语法原型(syntactic stem)
            + 使用一般规则与例外处理
            + 处理结果仍然为词
            + 处理过程要考虑词性的不同
        + 停用词(Stop Words)
            + 不具有内容信息的词
            + 停用词表依赖于具体文档集及具体应用
            + 过滤停用词的原因
                + 停用词并不能提高检索效果
                + 可以大幅减少索引大小
                + 减少检索时间
        + 大部分互联网搜索引擎并不使用 stemming/lemmatizatoin
            + 文档集很大
            + 不太考虑召回率
            + Stemming 结果并不完美
        + 大部分互联网搜索引擎使用停用词表
        + 无法从词袋表示恢复原文档
        + 优点: 简单、有效
        + 缺点: 忽略了词之间和句法关系以及篇章结构的信息

### 文档索引

+ 目的在于提高检索效率
+ 索引对象的选择
+ Phrase 识别比较困难，并不能显著提高检索效果
+ 通常采用 word 构建索引
+ 索引压缩: 减小索引大小
+ 动态索引: 索引库的动态维护、更新
+ 分布式索引: 索引信息分布在不同机器上
+ 具体细节参阅 Lucene 开源检索系统的相关代码

#### 倒排索引(inverted index)

+ 以关键词为核心对文档进行索引
+ 帮助快速地找到文档中所包含的关键词
+ 可看做连标数组，每个链表的表头包含关键词，其后序单元则包括所有包括这个关键词的文档标号，以及一些其他信息，如该词的频率和位置等
+ 优势
    + 关键词个数比文档少，因此检索效率高
    + 特别适合信息检索
+ 数据结构
    + 关键词查询一般采用 B-Tree 或哈希表
    + 文档列表组织一般采用二叉搜索树

### 文本信息检索模型

+ 基本思想: 如果一篇文档与一个查询相似，那么该文档与查询相关
+ 相似性
    + 字符串匹配
    + 相似的词汇
    + 相同的语义
+ 检索模型
    + 对实际检索过程的抽象和建模
    + 终极目标是基于语义进行匹配

#### 布尔模型(Boolean Model)

+ 基于布尔代数
+ 优点
    + 简单
    + 对查询严格掌控
+ 缺点
    + 一般用户难以构造布尔查询
    + 检索结果文档无法排序
    + 严格匹配，导致过少或过多的检索结果
+ 尽管布尔模型不再用作主流文档检索模型，但其思想常用于实现高级(综合)检索功能

#### 向量空间模型(Vector Space Model)

+ 现代信息检索系统中比较常用的检索模型
+ 特性
    + 用户输入自由文本作为查询
    + 对文档进行排序
    + 匹配准则放松
+ 思想: 文档与查询都是高维空间中的一个向量
+ 向量空间表示
    + 文档是词语组成的向量
    + 词语是文档组成的向量
    + 查询是词语组成的向量
+ 相似性
    + 用内积衡量
        + 缺点
            + 长文档由于更可能包含匹配词语，因而更可能相关
            + 然而，如果两篇文档具有同样的相似值，用户更倾向于短文档，短文档更聚焦在用户信息需求上
        + 相似性计算中应该考虑文档长度(进行规范化)
    + 用夹角来衡量
        + 向量归一化
        + 余弦度量(Cosine Measure)
        + 余弦相似度(Cosine Similarity)
+ 词语权重
    + 之前采用二值表示: 非 1 即 0
        + 没有反映词语频率
        + 假定所有词语均同等重要
    + tf: 词语出现的频率
        + tf~i,j~ = frequency of term i in document j
    + idf: 区别不同词语的重要性
    + tfidf
+ 其他相似性度量
    + Minkowski metric(dissimilarity)
    + Euclidian distance(dissimilarity)
    + Jacquard measure
    + Dice's coefficient

#### 概率模型(Probabilistic Model)

+ 1977 年由 Stephen Robertson 提出

### 信息检索评价

+ 评鉴检索模型或搜索引擎的性能
+ 搜索质量 vs 搜索效率
+ 对搜索质量的评价
    + 评测数据集
    + 评测指标
+ 相关评测
    + TREC
        + trec.nist.gov
        + 最具影响力
        + 多种信息检索任务，侧重于英文
    + NTCIR
        + research.nii.ac.jp/ntcir/
    + CLEF
        + www.clef-campaign.org
+ 评测数据集
    + 一般人工构建
    + 构成
        + 较大规模的文档集合 D
        + 查询集 Q 以及每个查询 q 对应的相关文档列表 REL~q~
+ 评价指标
    + 衡量检索结果与标准答案的一致性
    + 对非排序检索的评价
        + 对检索结果集合进行整体评价
        + 准确率(precision)与召回率(recall)，通常相互依赖
        + F 值(F-measure)
    + 对排序结果的评价
        + 考虑相关文档在检索结果中的排序位置
        + 在不同 recall levels 的 precision 值
        + 沿着检索结果列表从头往后考察
    + 对多级排序检索的评价
        + NDCG - Normalized Discounted Cumulative Gain

---

## Web 检索

Web 检索 = 文档检索 + 针对 Web 检索的新技术

### Web 页面采集

+ Web Crawler, spider
    + 快速有效地收集尽可能多的有用 Web 页面，包括页面之间的链接结构
+ Web 爬虫需要具备的特性
    + 健壮 robustness, 避免 spider traps
    + 友好 politeness, 遵守 web server 的采集协议
    + 分布式 distributed, 多台机器分布式采集
    + 可扩展 scalable, 爬虫架构方便扩展
    + 性能与效率，有效利用系统资源
    + 质量 quality, 倾向于采集有用的页面
    + 新颖 freshness, 获取网页的最新版本
    + 可扩充 Extensible, 能够处理新数据类型、新的采集协议等
+ Web 页面爬取策略
    + 深度优先
    + 广度优先
    + 实际应用中以广度优先为主，深度优先为辅
+ 难点
    + 暗网的采集，只有向数据库提交查询才形成的 Web 页面
    + Web 2.0 内容，脚本语言等生成的动态内容
    + 多媒体内容

### Web 页面排序

+ 与查询相似度最大的网页并不一定是最好的结果
+ 用户对 Web 页面的期望
    + 易于理解，可靠，作为查询话题的入口，能够回答差群的信息需求
+ 基于相关度的排序
    + 计算查询与页面内容的相似程度(依据文档检索模型)
+ 基于重要性的排序
    + 基于链接分析计算
+ 综合排序
    + 页面排序值 = 页面内容相关度 +/* 页面重要性

### Web 链接分析

+ Web 页面之间的超链关系非常重要
+ 一条从页面 A 指向页面 B 的链接表明
    + A 与 B 相关
    + A 推荐/引用/投票/赞成 B
+ 经典算法
    + HITS[Kleinberg, 1997] - Hypertext Induced Topic Selection
    + PageRank[Page & Brin, 1998]
+ 排序沉入(Rank Sink)
    + 形成 loop, 没有 outlink
    + 页面 A 与 B 相互提高 Rank, 而不向外分发 Rank

### 基于学习的网页排序

+ Learning to Rank 主流算法
    + RankSVM
    + RankNet
    + ListNet
+ Learning to Rank 工具包
    + RankLib
    + people.cs.umass.edu/~vdang/ranklib.html

### 搜索引擎优化(SEO)

+ Search engine optimization
    + 提高网站或网页在搜索引擎中可见度(排名)的过程
+ 基本思想
    + 基于各类搜索引擎的工作原理(采集、索引、排序等)，对网站进行相关的优化的调整，提高网站在搜索引擎中的排名
    + 白帽：合理优化，不牺牲用户体验
    + 黑帽：不正当优化，牺牲用户体验
        + 重复、隐藏文字、链接工厂、桥页、跳页
+ 影响排名的因素
    + 内部因素
        + URL 中出现关键词
        + 网页 Title 中出现关键词
        + 常规内容中出现关键词
        + 在页面的最后一段中出现关键词
        + `<Head>` 标签 比如 h1, h2 中出现关键词
        + 站内的链接中出现关键词
        + 导向相关内容的导出链接
        + 导出链接中出现关键词
        + 图片文件名中出现关键词
        + Alt 标签中出现关键词
        + comment 中出现关键词
        + 合理的频率更新内容
        + 内容对搜索引擎的展示位置
        + 网站结构循环 PR, 而非散发 PR
        + 关键词进行适当的修饰(加粗、斜体等)
    + 外部因素
        + 大量的导入链接
        + 从高 PR 值的网页获得导入链接
        + 从相关内容网站获得导入链接
        + 导入链接指向的网页有具体内容
        + 锚文字中有关键词
        + 锚文字周围有相关词
        + 锚文字存在于文章或句子中
        + 导入链接的时间长度，一般导入链接的存在时间有3-6个月
        + 单向链接的价值高于交换链接
        + 导入链接的页面的导出链接小于 100 个，流出链接越少越好
        + 链接来自不同 IP
        + 合理的导入链接增长频率
+ SEO 操作
    + 站外 SEO
        + 网站外部链接优化、网站的链接见识、网站的外部数据分析等
        + 交换、购买链接，提交网址到分类目录等
    + 站内 SEO
        + 网站结构的设计、网站代码优化和内部链接优化、网站内容的优化、网站用户体验优化等
        + 丰富网站关键词、主题集中、友好的网页结构、避免重复、有规律的更新等

---

## 自然语言处理基础

又称**自然语言理解**，是人工智能和语言学领域的分支学科。利用计算机对人类特有的书面形式和口头形式的自然语言进行各种类型处理和加工的技术。

自然语言生成：利用计算机自动生成可理解的自然语言文本的技术

### 基本任务

+ 关键任务
    + 自动分词
    + 命名实体识别
    + 词性标注
    + 句法分析
    + 语义分析
    + 篇章分析
+ 应用型任务
    + 机器翻译 Translation
    + **文本分类** Classification
    + 情感分析
    + 信息检索与过滤 Mining/Retrieval
    + 自动问答 Question Answering
    + **信息抽取** Extraction
    + **自动文摘** Summarization
    + 人机对话 Dialogue

### 为什么如此之难

+ 自然语言与生俱来的歧义问题
+ 自然语言中存在未知的语言现象
    + 新的词汇
    + 新的含义
    + 新的用法和语句结构
+ 人类用语言进行社会交流时会省略公有制是，但机器很难获取及更新世界知识

### 推荐教材

+ Foundations of Statistical Natrual Language Processing
+ Speech and Language Processing
+ 统计自然语言处理

### 汉语自动分词

一般认为：词是最小的、能够独立运用的、有意义的语言单位

**汉语分词的挑战**

+ 词和词组的边界模糊
+ 新词(未登陆词)
+ 切分歧义
    + 汉字串 AJB 被称作**交集型切分歧义**，如果满足 AJ, JB 同时为词，此时汉字串 J 被称作交集串
    + 汉字串 AB 被称作**组合型切分歧义**，如果满足条件 A, B, AB 同时为词
    + 真歧义：存在两种或两种以上的真实存在的切分形式

**分词方法**

+ 简单的模式匹配
    + 正向最大匹配(FMM)、逆向最大匹配(BMM, 比正向更有效)、双向匹配(BM, 比较两种方法的结果，大颗粒词越多越好，非词典词和单子词越少越好，可以识别出交叉歧义)
+ 基于规则的方法
    + 最少分词算法
+ 基于统计的方法
    + 统计语言模型分词、串频统计和词形匹配相结合的汉语自动分词、无词典分词
    + 第一步是候选网格构造：利用词典匹配，列举输入句子所有可能的切分词语，并以词网格形式保存
    + 第二步计算词网格中的每一条路径的权值，权值通过计算图中的每一个节点(每一个词)的一元统计概率和节点之间的二元统计概率的相关信息
    + 最后根据图搜索算法在图中找到一条权值最大的路径，作为最后的分词结果
    + 优缺点：可利用不同的统计语言模型计算最优路径，具有比较高的分词正确率；但算法时间、空间复杂度较高

### 词性标注(POS Tagging)

+ 为句子中的每个词语标注词性(part-of-speech marker)
+ 可看做是词法分析的关键任务，也可看做是句法分析的最低层次
+ 对后续句法分析、词义消岐等任务非常有用

### 句法分析

+ 句法/成分/短语结构分析 vs 依存关系分析
+ 完全分析 vs 局部分析/浅层分析
+ Context Free Grammars(CFG)

---

## 数据挖掘概述与关联规则挖掘

数据挖掘从多学科领域发展而来：Statistics/AI, Machine Learning, Pattern Recognition, Database systems

### 数据挖掘流程

**Data** -Selection-> **Target data** -Preprocessing-> **Preprocessed data** -Transformation-> **Transformed data** -Data mining-> **Patterns** -Interpretation/evaluatoin-> **Knowledge**

### 数据挖掘任务

+ 预测型(Prediction Methods): 基于一些变量预测其他变量的未知值或未来值
    + 分类 Classification
    + 回归 Regression
    + 偏差检测 Deviation Detection
+ 描述型(Description Methods): 发现描述数据的人们可解释的模式
    + 聚类 Clustering
    + 关联规则挖掘 Association Rule Discovery
    + 摘要 Summarization

### 关联规则挖掘：定义

关联规则反映一个事物与其他事物之间的相互依存性和关联性。如果两个或者多个事物之间存在一定的关联关系，那么其中一个事物就能够通过其他事物预测到。关联规则表示了项之间的关系。

+ 给定一个记录集合，每个记录包含若干项
    + 产生依赖规则，可以基于某些项的出现预测一个项的出现

应用：市场营销

+ 假如发现一条规则
+ {面包圈..} -> {薯片}
+ 可以帮助提高薯片的销量

### 摘要

为数据集进行总结，提供一个简洁/紧凑的表示，包括可视化与报表生成

### 回归

+ 基于若干变量的值预测一个给定的具有连续值的变量的值
    + 假设一个线性或非线性的依赖模型
+ 举例
    + 基于广告开支预测新产品的销售额
    + 基于温度、湿度、气压等预测风速
    + 预测股票指数

为数据预测一个连续值，确定两种或两种以上变量间的相互依赖关系。

+ 最简单的情形: 一元线性回归
    + 只包括一个自变量 x 和一个因变量 y，且二者的关系可用一条直线近似表示
    + 回归分析的目标为找一个线性函数迎合训练数据
    + 可采用最小二乘法
+ 其他回归方法
    + Logistic 回归
    + 岭回归
    + 支持向量回归
+ 回归结果评价
    + 均方误差(Mean Squared Error, MSE)
    + 均方根误差(root mean square error, RMSE)

### 偏差/异常检测

+ 从正常行为中检测显著的偏差/异常
+ 举例
    + 信用卡欺诈检测
    + 网络入侵检测

### 数据挖掘工具

+ Free open-source software and application
    + Weka
    + GATE
    + Carrot2
    + NLTK
    + Orange
    + RapidMiner
    + KNIME
+ Commercial software
    + IBM InfoSphere Warehouse
    + Microsoft Analysis Services
    + SAS Enterprise Miner
    + STATISTICA Data Miner
    + Oracle Data Mining

### 数据挖掘的挑战

+ 可拓展性
+ 挖掘高维数据、高速数据流
+ 挖掘序列数据、时间序列数据
+ 从复杂、异构、网络化数据中挖掘复杂知识
+ 挖掘低质量数据
+ 安全性、隐私保护

---

## 分类

将数据划分到已知类别。分类器的构建基于有监督学习(标注数据:训练集)

+ 给定一个样例集合(训练集)
    + 每个样例包含一个属性集合，其中一个属性是类标记/类号
+ 基于训练集构建一个模型，该模型将类标记属性看作是其它属性值的一个函数
+ 目标：对心的样例尽可能准确地赋予标记
    + 基于一个测试集来评估模型的准确性

Training Set -> Learn Classifier -> Model <- Test set

+ 二类分类：正、负
+ 多类分类：多类(>=3)

二类分类是分类问题的最基本形式，多类分类问题可通过转化为二类分类问题加以解决。

+ One vs. One
    + 对于 K 类分类需要 K(K-1)/2 个二类分类器
    + 测试分类时采用投票方式确定类别
    + E.g. Labels: a, b, c
    + 分类器: a vs b, b vs c, a vs c
+ One vs. All(Rest):
    + 对于 K 类分类需要 K 个二类分类器
    + 测试分类时取返回最大值的类别
    + E.g. Labels: a, b, c
    + 分类器: a vs (b, c), b vs (a, c), c vs (a, b)

层次式分类，类别构成层次式结构(树状)。中图法、ODP目录。

+ 应用
    + 新闻分类
    + 广告页面判别
    + 垃圾邮件过滤
    + 垃圾短信过滤
    + 博客风格判断
    + 评论情感分析

### 基于规则的分类

人工/专家制定分类规则，使用布尔操作符(AND, OR, NOT)，可将规则组织成决策树，节点代表规则，叶节点代表类别

+ 优势
    + 透明，易于理解，易于修改
+ 劣势
    + 复杂，耗时
    + 主要依赖人工/专家的智能，而非系统/机器智能
    + 不易拓展
    + 绝对的类别划分，无置信度

### 基于统计的分类

+ 优势
    + 可以输出置信概率、允许阈值控制、可扩展
+ 劣势
    + 需要已标注好的训练数据
+ 典型方法
    + 朴素贝叶斯
    + Rocchio
    + K 近邻
    + 支持向量机

### 文本统计分类流程

+ 预处理
    + Tokenization
    + Filtering
    + Stemming
+ 特征计算
    + tf
    + Log(tf+1)
    + tfidf
+ 特征选择
    + MI
    + Chi-Square
    + Information Gain
+ 分类学习
    + SVM
    + Rocchio
    + Naive Bayes
+ 结果评估
    + Recall
    + F-Measure
    + Precision

### 文本分类-特征向量表示

+ 文本表示为特征向量
    + 词语(term): 基本单元
    + 权重 TF * IDF
        + TF: 词频
        + IDF: log(N/DF), N 为文档总数量，DF 为包含该词语的文档数量

### 文本分类-特征选择

+ 好处
    + 减少特征维数，改善效果
    + 防止过拟合，增强模型的泛化能力
    + 提高学习效率
    + 提高模型的可解释性
+ 方法，从原有特征集合中找出一个更加有效的子集
    + Document Frequency 文档频率
        + 词语的 DF 小于某个阈值去掉(太小，没有代表性)
        + 词语的 DF 大于某个阈值也去掉(太多，没有区分度)
    + Mutual Information 互信息
        + MI 越大词语 t 和 c 共现程度越大
    + Information Gain 信息增益
        + 词语 t 为整个分类所能提供的信息量(不考虑任何特征的熵和考虑该特征后的熵的差值)
    + Information Ratio
    + Chi Squrae
    + Odd Ratio

### 朴素贝叶斯分类

+ 基于概率理论的学习和分类方法
+ 贝叶斯理论充当重要角色
+ 分类是根据给定样本描述的可能的类别基础上产生的后验概率分布
    + 基于贝叶斯理论来计算后验概率
+ 分类原理：最大后验估计 MAP(maximum posteriori)

### Rocchio 分类方法

+ 使用中心向量(centroid vector)表示一个类别
    + 中心向量为某个类别下所有文档向量的平均向量
    + 基于训练集计算
+ 对于新文档，计算该文档与每个类别的中心向量的距离/相似度
    + 基于余弦测度
+ 确定其类别为距离最小/相似性最大的类别
+ 优势: 训练快速，模型很小，快速分类
+ 劣势: 类别数量增加时准确率降低

### K 近邻分类方法

+ 与 Rocchio 方法类似
+ 检查新文档的 k 个近邻向量，利用这些近邻向量的类别来确定该文档的类别
    + K 通过实验确定
    + “近邻” 通过相似度/距离测度来定义
+ 1 近邻分类方法
    + 将新文档划分到与其最相近的文档样例所属的类别
+ K 近邻分类方法
    + 基于投票机制，将新文档划分到 k 个近邻文档中多数文档所属的类别
    + 进一步，基于加权投票机制，根据近邻文档的相近程度，赋予每个近邻文档一定的权重
+ 优势
    + 不需要训练阶段
    + 类别数量增加也具有良好的扩展性
+ 劣势
    + 训练数据很大时模型很大
    + 需要大量内存
    + 性能较慢

### 支持向量机 Support Vector Machine

+ 对于二类分类，该方法在向量空间中找出一个决策超平面(分类函数 f(x) = wx + b)，对属于两个类别的文档向量进行有效粉绿
    + 通常有很多可能的分割超平面
    + 找到最好的一个超平面: 最大间隔准则
        + 使得属于不同类别的数据点间隔最大
    + 间隔区边缘上的向量称为支撑向量
+ 实际上要求解一个带约束的二次规划(quadratic programming, QP)问题
+ 训练结果
    + 支撑向量
+ 分类
    + 计算新文档向量与支撑向量的距离
+ 常用工具
    + SVMLight
    + LIBSVM
+ 优势
    + 只有支撑向量用来对新文档分类
    + 模型小
    + 一般不会过拟合
+ 劣势
    + 训练过程非常复杂: 优化问题

### 分类结果评估

+ 对每个分类都可以计算出 precision, recall, F-measure
    + 一般侧重正例的结果
+ 总体评价: 精度(Accuracy) = 正确分类的样本数量 / 总样本数量

### 如何应用于实际

+ 大多数应用都是直接采用已有的分类算法与工具
    + 不需要开发新的
+ 关键在于特征工程
    + 针对特定应用问题寻找合理、有效的特征集
+ 一般需要调节分类算法与工具的多个参数
    + 比如 KNN 中的 K，SVM 中的 C 参数等

---

## 聚类

+ 给定一个数据点集合，每个数据点具有一组属性，数据点之间能进行相似度度量，聚类目标为找到若干类簇：
    + 同一类簇中的数据点相似
    + 不同类簇中的数据点不相似
+ 无监督学习
    + 没有标注数据
    + 类簇未知
+ 相似度度量准则
    + 欧氏距离(L2 norm)
    + 余弦准则
    + L1 范式(L1 norm)
+ 聚类算法
    + K-Means 聚类
    + 层次式聚类(Hierarchical clustering)
    + 增量式单遍聚类
    + 基于图分割的聚类
    + 基于密度峰值的聚类

应用：文档聚类

+ 目标：发现文档类簇，同一类簇中文档相似(基于重要词语)
+ 方法：识别每篇文档中的重要词语，基于文档相似性进行聚类

### 层次式聚类

+ 自底向上的凝聚式聚类(Agglomerative clustering)
    + 初始每个文档自成一个类簇
    + 每次合并最相似/距离最近的两个类簇，形成一个新类簇，循环执行，直到满足终止条件
        + 终止条件为类簇数量或者相似度阈值
    + 结果为树形图
+ 不同的计算类簇间距离/相似性的方法
    + 最小距离(single link)
    + 最大距离(complete link)
    + 平均距离(group average)
+ 自顶向下的划分式聚类(Divisive clustering)
    + 初始只有一个类簇，包括所有文档
    + 每次从当前类簇中选择最大(或最不合理)的一个类簇，将其分割成两个(或多个)新的类簇，循环执行，直到满足终止条件
        + 类簇分割方法可以采用其他聚类方法，比如 K 均值算法等

### K 均值(K-means)聚类

+ 一种基于划分的聚类算法
+ 算法将文档集划分到 k 个类簇中
    + 每个类簇有一个类簇中心，称为 centroid
    + 可基于该类簇文档向量的平均向量计算
+ K 由用户指定

### Buckshot 算法

结合 K-means 与凝聚式聚类

+ 从原始 n 个数据点中随机取 √n 个数据点
+ 针对这些样本数据点上运行凝聚式聚类
+ 使用凝聚式聚类结果作为初始种子点
+ 在元数据上基于初始种子点运行 K-means

改善了种子点的选择

### 增量式单遍聚类(Single-Pass)

+ 增量式聚类，适合于高效处理动态文本数据流
+ 将新文档与已有类簇逐一对比，如果与某个类簇的相似度值大于设定的阈值，那么将该文档归并到相应类簇中，否则基于该文档形成一个新的类簇
    + 数据流中第一个文档形成第一个类簇

### 基于图分割的聚类

+ 计算文档对之间的相似度值，构建相似度图 G=(V,E)
    + 每个文档为图的一个节点
    + 文档之间有边连接，边的权重 W 为文档相似度
+ 文档聚类问题转换成在图上进行顶点分割的问题
+ 切割标准 min cut(A,B)
+ 问题
    + 只考虑了类簇之间的连接情况
    + 没有考虑类簇内部的密度
+ 改进方法: Normalized Cut

### 基于密度峰值的聚类(Science)

+ 简单优美，可自动确定聚类数目，检测孤立点，可识别不同形状的聚类
+ 假设: 类簇中心被一些局部密度较低的点围绕，并且这些点距离其他有高局部密度的点的距离都比较大
+ 聚类过程
    + 计算出所有数据点的局部密度值和到高局部密度点的距离后，可以得到一张决策图
    + 在决策图上挑选具有较大密度的样本点作为类簇中心
    + 将其他样本点按照局部密度从高到底依次确定所属类簇，其类簇为领域内最近的高于该点局部密度的样本点所处的类簇

### 半监督聚类

除了带聚类的数据，还提供了少量先验知识

+ 部分标注信息
    + 例如为若干数据点标注了类簇
+ 约束信息
    + 例如要求某两个数据点必须在同一类簇，或者某两个数据点不能在同一类簇
+ Seeded K-means
    + 用户提供了 Seeded points
    + 利用提供的标注信息(seeded points)寻找初始类簇中心，然后运行 K-means
    + Seeded points 的标签可能会改变
+ Constrained K-means
    + 用户提供了 Seeded points
    + 利用提供的标注信息(seeded points)寻找初始类簇中心，然后运行 K-means
    + Seeded points 的标签不允许被改变

### 聚类结果评估

+ 基于人工标注的类簇进行评价
+ 评价准则包括: F 值、纯度(Purity)、规范化信息(NMI)

### 聚类算法的选择

+ 聚类算法的选择具有挑战性
    + 每种算法都有各自的优势与不足，聚类效果通常依赖于聚类算法、距离函数、具体的数据与应用
+ 实际做法
    + 运行使用不同距离函数的多个聚类算法，分析和比较聚类结果
+ 对聚类结果的解释要基于原始数据的意义以及聚类算法的特性

### 半监督聚类

+ COP K-means
    + 用户提供了 must-link 与 cannot-link 约束
    + 初始化: 类簇中心随机选择，但必须保证满足 must-link 约束，也就是 must-link 的两个数据点不能选择做为不同类簇的中心
    + 算法: 一个数据点必须在不违反任何约束的情况下归属到临近的类簇

### 检索结果聚类

+ 两类方法
    + 先对 snippet 进行聚类，然后为每个类簇选择标签
    + 先分析获取有意义的类簇标签，然后将检索结果划分到不同标签
+ 基于后缀树的检索结果聚类(Suffix Tree Clustering, STC)
    + 时间复杂度低，高效
    + 容易获得每个类簇的关键词标签
    + 允许一个文档属于多个类簇
+ 基于回归学习的检索结果聚类
    + 现货的重要的短语代表类簇，然后再将检索结果跟类簇关联
    + 同样允许一文档隶属多个类簇
    + 候选短语(频率大于3的n-gram(n<=3))
    + 短语重要性排序
        + 看做回归问题
        + 利用 SVM-Light 实现的支撑向量回归等多个回归方法
        + 人工标注短语训练集，也即短语与其重要性分值
    + 短语特征
        + Phrase Frequency/Inverted Document Frequency(TFIDF)
        + Phrase Length
        + Intra-Cluster Similarity
        + Cluster Entropy
        + Phrase Independence

---

## 智能问答基础技术

起源于信息检索社区。根据用户的提问给出简短的答案，有时需要提供答案的证据。

### 问题类型

+ 根据答案类型划分
    + 事实型问题(Factual questions)
    + 观点型问题(Opinions)
    + 摘要型问题(Summaries)
+ 根据问题言语行为(question speech act)划分
    + 是否型问题(Yes/NO questions)
    + WH 问题(WH questions)
    + 间接请求(Indirect Requests)
    + 命令(Commands)
+ 复杂/困难问题
    + 为什么/怎么样(Why, How questions)
    + 什么(What questions)

### 主要技术

+ 传统自动问答技术
    + 基于语料库的自动问答
        + 问题分析(分类、模板匹配、语义分析)
        + 段落检测(段落抽取、排序)
        + 答案抽取(实体识别、模板匹配、排序)
    + 基于知识库的自动问答
+ 社区问答技术
    + 问题分类、问题推荐
    + 专家发现、信誉评估
    + 知识抽取

---

## 互联网信息抽取

**非结构化数据**(纯文本，句子，查询字符串) 和**半结构化数据**(HTML文档，查询日志，词典) -IE-> **结构化数据**(语义知识)

+ 网页主要文本抽取(BTE)方法
    + 识别出一个包含最多词语(排除最多标签)的连续区域
+ 基于文本标签比例的抽取方法(CERT, Content Extraction via Tag Ratios)
    + 绘制文本标签直方图
    + 对文本标签直方图进行变换，并进行聚类，得到网页内容
+ 基于网页分块重要性识别的抽取方法(Learning Block Importance Models for Web Pages)
    + 首先将网页分为块状区域(VIPS, 基于视觉的网页分块算法)
    + 然后对每块区域判断重要性
+ 基于模板的方法
    + 基于批量处子统一模板的网页来自动检测模板
    + 利用模板抽取网页内容

### 文本语义信息抽取

**主要任务**

+ 命名实体抽取(Named entity extraction)
    + 命名实体识别(Named entity recognitoin, NER)
    + 共指消解(Co-reference resolution)
+ 属性抽取(Attribute extraction)
+ 关系挖掘(Relation mining)
    + 相关短语和实体(Related terms and entities)
    + 归类(Categorization)
    + 关系检测与分类(Relation detection and classification)
+ 事件挖掘(Event mining)
    + 事件检测与分类(Event detection and classification)

### 实体识别

+ 识别文本中出现的实体
    + MUC(1997): Person, Location, Organization, Date/Time/Currency
    + ACE(2005): 100 多种更具体的类型
+ 人工规则 vs 机器学习方法
+ 针对不同试题类型与领域考虑不同方法
    + 封闭类(e.g., geographical locations, disease names, gene & protein names): 人工规则 + 词典
    + 语法相关(e.g., phone numbers, zip codes): 正则表达式
    + 语义相关(e.g., person and compnay names): 综合考虑上下文，句法特征，词典，启发式规则等
    + 对于典型的实体类型抽取效果已经较好

### 语义类挖掘

+ 目标：发现同位短语(coordinate terms), 类似于可比实体发现
+ 主要方法
    + 一阶共现(First-order co-occurrences): 普通共现 & 模板
    + **二阶共现(Second-order co-occurrences)**: 分布式相似性
        + 分布式假设：出现在相似上下文(词语、句法)中的词语比较相似

**基于分布相似性(DS)**

+ 定义上下文：句法上下文，词语上下文
+ 将每个短语表示为一个特征向量
    + 特征：短语出现的一个上下文
    + 特征值：上下文针对短语的权重
+ 计算短语相似性
    + 特征向量之间的相似性

**语义层级构建**

+ 主要子任务
